#!/usr/bin/env python3
"""
í†µí•© API ìƒì„±ê¸° í…ŒìŠ¤íŠ¸
GraphQLê³¼ OpenAPIë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šê³  RAG ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¼ ìë™ìœ¼ë¡œ íŒë‹¨
"""

import pytest
import json
import yaml
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
from unittest.mock import Mock, patch
import requests

# LLM ê´€ë ¨ import
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# RAG ê´€ë ¨ import
try:
    from langchain_community.embeddings import OpenAIEmbeddings
    from langchain_community.vectorstores import Chroma
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False

class APIClient:
    """ì‹¤ì œ API í˜¸ì¶œì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
    
    def execute_graphql(self, query: str, variables: Dict[str, Any] = None) -> Dict[str, Any]:
        """GraphQL ì¿¼ë¦¬ ì‹¤í–‰"""
        url = f"{self.base_url}/graphql"
        payload = {
            "query": query,
            "variables": variables or {}
        }
        
        try:
            response = self.session.post(url, json=payload, headers={
                "Content-Type": "application/json"
            })
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            return {"error": f"GraphQL ìš”ì²­ ì‹¤íŒ¨: {e}"}
    
    def execute_openapi(self, request_config: Dict[str, Any]) -> Dict[str, Any]:
        """OpenAPI HTTP ìš”ì²­ ì‹¤í–‰"""
        method = request_config.get("method", "GET").upper()
        url = request_config.get("url", "")
        headers = request_config.get("headers", {})
        params = request_config.get("params", {})
        body = request_config.get("body", {})
        
        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° base_urlê³¼ ê²°í•©
        if url.startswith('/'):
            full_url = f"{self.base_url}{url}"
        elif url.startswith('http'):
            full_url = url
        else:
            full_url = f"{self.base_url}/{url}"
        
        try:
            if method == "GET":
                response = self.session.get(full_url, headers=headers, params=params)
            elif method == "POST":
                response = self.session.post(full_url, headers=headers, params=params, json=body)
            elif method == "PUT":
                response = self.session.put(full_url, headers=headers, params=params, json=body)
            elif method == "DELETE":
                response = self.session.delete(full_url, headers=headers, params=params)
            elif method == "PATCH":
                response = self.session.patch(full_url, headers=headers, params=params, json=body)
            else:
                return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” HTTP ë©”ì„œë“œ: {method}"}
            
            response.raise_for_status()
            return {
                "status_code": response.status_code,
                "headers": dict(response.headers),
                "data": response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text
            }
        except requests.exceptions.RequestException as e:
            return {"error": f"OpenAPI ìš”ì²­ ì‹¤íŒ¨: {e}"}

class IntegratedAPIGenerator:
    """í†µí•© API ìƒì„±ê¸° - GraphQLê³¼ OpenAPIë¥¼ ìë™ìœ¼ë¡œ íŒë‹¨"""
    
    def __init__(self, openai_api_key: str = None, rag_index_path: str = "rag_data/chroma_db"):
        self.openai_api_key = openai_api_key
        self.rag_index_path = Path(rag_index_path)
        
        # LLM ì´ˆê¸°í™”
        if OPENAI_AVAILABLE and openai_api_key:
            self.llm = OpenAI(api_key=openai_api_key, temperature=0)
        else:
            self.llm = None
        
        # RAG ì¸ë±ìŠ¤ ë¡œë“œ
        self.documents = self._load_rag_documents()
        
        # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (ì„ íƒì‚¬í•­)
        if LANGCHAIN_AVAILABLE and openai_api_key:
            self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
            self._init_vectorstore()
        else:
            self.embeddings = None
            self.vectorstore = None
    
    def _load_rag_documents(self) -> List[Dict[str, Any]]:
        """RAG ì¸ë±ìŠ¤ì—ì„œ ë¬¸ì„œë“¤ì„ ë¡œë“œ - ê¸°ì¡´ Chroma ë°©ì‹"""
        documents = []
        
        # ê¸°ì¡´ Chroma ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ë¬¸ì„œ ë¡œë“œ
        if LANGCHAIN_AVAILABLE and self.openai_api_key:
            try:
                chroma_path = self.rag_index_path
                if chroma_path.exists():
                    vectorstore = Chroma(
                        persist_directory=str(chroma_path),
                        embedding_function=self.embeddings
                    )
                    
                    # ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (ì„ì‹œë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‚¬ìš©)
                    results = vectorstore.similarity_search("", k=1000)  # ì¶©ë¶„íˆ í° ìˆ˜
                    for doc in results:
                        documents.append({
                            "content": doc.page_content,
                            "metadata": doc.metadata
                        })
            except Exception as e:
                print(f"Chroma ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return documents
    
    def _init_vectorstore(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” - ê¸°ì¡´ Chroma ë°©ì‹"""
        try:
            chroma_path = self.rag_index_path
            if chroma_path.exists():
                self.vectorstore = Chroma(
                    persist_directory=str(chroma_path),
                    embedding_function=self.embeddings
                )
            else:
                self.vectorstore = None
        except Exception as e:
            print(f"Chroma ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.vectorstore = None
    
    def search_relevant_apis(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ APIë“¤ì„ ê²€ìƒ‰ - ê¸°ì¡´ Chroma ë°©ì‹"""
        if self.vectorstore:
            # ê¸°ì¡´ Chroma ë²¡í„° ê²€ìƒ‰ ì‚¬ìš©
            results = self.vectorstore.similarity_search(query, k=top_k)
            return [{"content": doc.page_content, "metadata": doc.metadata} for doc in results]
        else:
            # ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return []
    
    def detect_api_type(self, search_results: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ API íƒ€ì… ê°ì§€"""
        graphql_count = 0
        openapi_count = 0
        
        for result in search_results:
            metadata = result['metadata']
            if metadata.get('type') == 'graphql':
                graphql_count += 1
            elif metadata.get('type') == 'openapi':
                openapi_count += 1
        
        # ë” ë§ì€ ê²°ê³¼ê°€ ìˆëŠ” íƒ€ì…ì„ ì„ íƒ
        if graphql_count > openapi_count:
            return 'graphql'
        elif openapi_count > graphql_count:
            return 'openapi'
        else:
            # ë™ì ì¸ ê²½ìš° ì²« ë²ˆì§¸ ê²°ê³¼ì˜ íƒ€ì… ì‚¬ìš©
            return search_results[0]['metadata'].get('type', 'graphql')
    
    def generate_graphql_query(self, query: str, relevant_apis: List[Dict[str, Any]]) -> str:
        """GraphQL ì¿¼ë¦¬ ìƒì„±"""
        if not self.llm:
            return "# GraphQL ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"
        
        # ê´€ë ¨ API ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        api_context = "\n\n".join([
            f"API: {api['metadata'].get('dsl_name', 'Unknown')}\n{api['content']}"
            for api in relevant_apis[:3]  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
        ])
        
        prompt = f"""
ë‹¤ìŒ GraphQL API ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ GraphQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

API ì •ë³´:
{api_context}

ìì—°ì–´ ì¿¼ë¦¬: {query}

GraphQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ë³€ìˆ˜ëŠ” $ë¡œ ì‹œì‘í•˜ê³ , ì ì ˆí•œ í•„ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.
"""
        
        try:
            response = self.llm.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"# GraphQL ì¿¼ë¦¬ ìƒì„± ì˜¤ë¥˜: {e}"
    
    def generate_openapi_request(self, query: str, relevant_apis: List[Dict[str, Any]]) -> Dict[str, Any]:
        """OpenAPI HTTP ìš”ì²­ êµ¬ì„± ìƒì„±"""
        if not self.llm:
            return {"error": "OpenAPI ìš”ì²­ ìƒì„± ì‹¤íŒ¨: LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"}
        
        # ê´€ë ¨ API ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        api_context = "\n\n".join([
            f"API: {api['metadata'].get('operation', 'Unknown')}\n{api['content']}"
            for api in relevant_apis[:3]  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
        ])
        
        prompt = f"""
ë‹¤ìŒ OpenAPI ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ HTTP ìš”ì²­ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

API ì •ë³´:
{api_context}

ìì—°ì–´ ì¿¼ë¦¬: {query}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ HTTP ìš”ì²­ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
{{
    "method": "HTTP_METHOD",
    "url": "BASE_URL/PATH",
    "headers": {{}},
    "params": {{}},
    "body": {{}}
}}

ê°€ëŠ¥í•œ HTTP ë©”ì„œë“œ: GET, POST, PUT, DELETE, PATCH
"""
        
        try:
            response = self.llm.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500
            )
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                return json.loads(response.choices[0].message.content.strip())
            except json.JSONDecodeError:
                return {
                    "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
                    "raw_response": response.choices[0].message.content.strip()
                }
        except Exception as e:
            return {"error": f"OpenAPI ìš”ì²­ ìƒì„± ì˜¤ë¥˜: {e}"}
    
    def generate_api_call(self, query: str) -> Dict[str, Any]:
        """í†µí•© API í˜¸ì¶œ ìƒì„± - íƒ€ì…ì„ ìë™ìœ¼ë¡œ ê°ì§€"""
        # ê´€ë ¨ API ê²€ìƒ‰
        relevant_apis = self.search_relevant_apis(query)
        
        if not relevant_apis:
            return {
                "error": "ê´€ë ¨ APIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "query": query
            }
        
        # API íƒ€ì… ê°ì§€
        api_type = self.detect_api_type(relevant_apis)
        
        # íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ìƒì„±ê¸° í˜¸ì¶œ
        if api_type == 'graphql':
            result = self.generate_graphql_query(query, relevant_apis)
            return {
                "type": "graphql",
                "query": result,
                "relevant_apis": [api['metadata'] for api in relevant_apis[:3]]
            }
        else:  # openapi
            result = self.generate_openapi_request(query, relevant_apis)
            return {
                "type": "openapi",
                "request": result,
                "relevant_apis": [api['metadata'] for api in relevant_apis[:3]]
            }

    def generate_api_call_without_llm(self, query: str, api_type: str) -> Dict[str, Any]:
        """í†µí•© API í˜¸ì¶œ ìƒì„± - íƒ€ì…ì„ ìë™ìœ¼ë¡œ ê°ì§€ (LLM ì—†ì´)"""
        # ê´€ë ¨ API ê²€ìƒ‰
        relevant_apis = self.search_relevant_apis(query)
        
        if not relevant_apis:
            return {
                "error": "ê´€ë ¨ APIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "query": query
            }
        
        # API íƒ€ì… ê°ì§€
        api_type = self.detect_api_type(relevant_apis)
        
        # íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ìƒì„±ê¸° í˜¸ì¶œ
        if api_type == 'graphql':
            result = self.generate_graphql_query(query, relevant_apis)
            return {
                "type": "graphql",
                "query": result,
                "relevant_apis": [api['metadata'] for api in relevant_apis[:3]]
            }
        else:  # openapi
            result = self.generate_openapi_request(query, relevant_apis)
            return {
                "type": "openapi",
                "request": result,
                "relevant_apis": [api['metadata'] for api in relevant_apis[:3]]
            }

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
def test_integrated_api_generator_initialization():
    """í†µí•© API ìƒì„±ê¸° ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    generator = IntegratedAPIGenerator()
    
    assert generator.documents is not None
    # ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ì–´ë„ ì´ˆê¸°í™”ëŠ” ì„±ê³µí•´ì•¼ í•¨
    print(f"âœ… ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(generator.documents)}")
    print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒíƒœ: {'ì‚¬ìš© ê°€ëŠ¥' if generator.vectorstore else 'ì‚¬ìš© ë¶ˆê°€'}")

def test_api_search():
    """API ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    generator = IntegratedAPIGenerator()
    
    # ë²¡í„°ìŠ¤í† ì–´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    if generator.vectorstore:
        # GraphQL ê´€ë ¨ ê²€ìƒ‰
        graphql_results = generator.search_relevant_apis("ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ")
        print(f"âœ… GraphQL ê²€ìƒ‰ ê²°ê³¼: {len(graphql_results)}ê°œ")
        
        # OpenAPI ê´€ë ¨ ê²€ìƒ‰
        openapi_results = generator.search_relevant_apis("ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰")
        print(f"âœ… OpenAPI ê²€ìƒ‰ ê²°ê³¼: {len(openapi_results)}ê°œ")
    else:
        print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ì–´ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        print("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

def test_api_type_detection():
    """API íƒ€ì… ê°ì§€ í…ŒìŠ¤íŠ¸"""
    generator = IntegratedAPIGenerator()
    
    # ë²¡í„°ìŠ¤í† ì–´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í…ŒìŠ¤íŠ¸
    if generator.vectorstore:
        # GraphQL ê²€ìƒ‰ ê²°ê³¼
        graphql_results = generator.search_relevant_apis("ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ")
        api_type = generator.detect_api_type(graphql_results)
        print(f"âœ… GraphQL íƒ€ì… ê°ì§€: {api_type}")
        
        # OpenAPI ê²€ìƒ‰ ê²°ê³¼
        openapi_results = generator.search_relevant_apis("ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰")
        api_type = generator.detect_api_type(openapi_results)
        print(f"âœ… OpenAPI íƒ€ì… ê°ì§€: {api_type}")
    else:
        print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ì–´ì„œ íƒ€ì… ê°ì§€ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        print("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

@pytest.mark.skipif(not OPENAI_AVAILABLE, reason="OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
def test_graphql_query_generation():
    """GraphQL ì¿¼ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸"""
    openai_api_key = os.getenv('OPENAI_API_KEY')
    if not openai_api_key:
        pytest.skip("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    generator = IntegratedAPIGenerator(openai_api_key)
    
    test_cases = [
        "test@example.com ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ",
        "ì‹œë‚˜ë¦¬ì˜¤ ëª©ë¡ ì¡°íšŒ",
        "ë³´ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"
    ]
    
    for query in test_cases:
        result = generator.generate_api_call(query)
        
        print(f"\n[ì…ë ¥ ì¿¼ë¦¬] {query}")
        print(f"[ê°ì§€ëœ íƒ€ì…] {result['type']}")
        
        if result['type'] == 'graphql':
            print(f"[ìƒì„±ëœ GraphQL ì¿¼ë¦¬]\n{result['query']}")
            assert 'query' in result['query'].lower() or 'mutation' in result['query'].lower()
        else:
            print(f"[ìƒì„±ëœ OpenAPI ìš”ì²­]\n{json.dumps(result['request'], indent=2, ensure_ascii=False)}")
        
        print(f"[ê´€ë ¨ APIë“¤] {[api.get('dsl_name', api.get('operation', 'Unknown')) for api in result['relevant_apis']]}")

@pytest.mark.skipif(not OPENAI_AVAILABLE, reason="OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
def test_openapi_request_generation():
    """OpenAPI ìš”ì²­ ìƒì„± í…ŒìŠ¤íŠ¸"""
    openai_api_key = os.getenv('OPENAI_API_KEY')
    if not openai_api_key:
        pytest.skip("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    generator = IntegratedAPIGenerator(openai_api_key)
    
    test_cases = [
        "ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰",
        "ì‹œë‚˜ë¦¬ì˜¤ ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ",
        "íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"
    ]
    
    for query in test_cases:
        result = generator.generate_api_call(query)
        
        print(f"\n[ì…ë ¥ ì¿¼ë¦¬] {query}")
        print(f"[ê°ì§€ëœ íƒ€ì…] {result['type']}")
        
        if result['type'] == 'openapi':
            print(f"[ìƒì„±ëœ OpenAPI ìš”ì²­]\n{json.dumps(result['request'], indent=2, ensure_ascii=False)}")
            assert 'method' in result['request'] or 'error' in result['request']
        else:
            print(f"[ìƒì„±ëœ GraphQL ì¿¼ë¦¬]\n{result['query']}")
        
        print(f"[ê´€ë ¨ APIë“¤] {[api.get('dsl_name', api.get('operation', 'Unknown')) for api in result['relevant_apis']]}")

def test_mixed_api_queries():
    """í˜¼í•© API ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ - íƒ€ì… ìë™ ê°ì§€"""
    openai_api_key = os.getenv('OPENAI_API_KEY')
    if not openai_api_key:
        pytest.skip("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    generator = IntegratedAPIGenerator(openai_api_key)
    
    test_cases = [
        {
            "query": "test@example.com ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ",
            "expected_type": "graphql"
        },
        {
            "query": "ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰",
            "expected_type": "openapi"
        },
        {
            "query": "ì‹œë‚˜ë¦¬ì˜¤ ëª©ë¡ ì¡°íšŒ",
            "expected_type": "openapi"
        },
        {
            "query": "ë³´ë“œ ì •ë³´ ìˆ˜ì •",
            "expected_type": "graphql"
        }
    ]
    
    for case in test_cases:
        result = generator.generate_api_call(case["query"])
        
        print(f"\n[ì…ë ¥ ì¿¼ë¦¬] {case['query']}")
        print(f"[ì˜ˆìƒ íƒ€ì…] {case['expected_type']}")
        print(f"[ì‹¤ì œ ê°ì§€ëœ íƒ€ì…] {result['type']}")
        
        # íƒ€ì… ê°ì§€ ì •í™•ë„ í™•ì¸ (ì„ íƒì‚¬í•­)
        if result['type'] == case['expected_type']:
            print("âœ… íƒ€ì… ê°ì§€ ì •í™•")
        else:
            print("âš ï¸ íƒ€ì… ê°ì§€ ë‹¤ë¦„ (ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ)")
        
        # ê²°ê³¼ ì¶œë ¥
        if result['type'] == 'graphql':
            print(f"[ìƒì„±ëœ GraphQL ì¿¼ë¦¬]\n{result['query']}")
        else:
            print(f"[ìƒì„±ëœ OpenAPI ìš”ì²­]\n{json.dumps(result['request'], indent=2, ensure_ascii=False)}")

@pytest.mark.skipif(not OPENAI_AVAILABLE, reason="OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
def test_actual_api_execution():
    """ì‹¤ì œ API ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
    generator = IntegratedAPIGenerator()
    
    # ë²¡í„°ìŠ¤í† ì–´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í…ŒìŠ¤íŠ¸
    if generator.vectorstore:
        # GraphQL ì¿¼ë¦¬ ì‹¤í–‰
        graphql_result = generator.execute_api_call(
            "ì‚¬ìš©ì ì •ë³´ë¥¼ ì¡°íšŒí•´ì¤˜",
            "graphql"
        )
        print(f"âœ… GraphQL ì‹¤í–‰ ê²°ê³¼: {graphql_result}")
        
        # OpenAPI ìš”ì²­ ì‹¤í–‰
        openapi_result = generator.execute_api_call(
            "ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤í–‰í•´ì¤˜",
            "openapi"
        )
        print(f"âœ… OpenAPI ì‹¤í–‰ ê²°ê³¼: {openapi_result}")
    else:
        print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ì–´ì„œ ì‹¤ì œ API ì‹¤í–‰ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        print("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

def test_api_generation_without_llm():
    """LLM ì—†ì´ API ìƒì„± í…ŒìŠ¤íŠ¸"""
    generator = IntegratedAPIGenerator()
    
    # ë²¡í„°ìŠ¤í† ì–´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í…ŒìŠ¤íŠ¸
    if generator.vectorstore:
        # GraphQL ì¿¼ë¦¬ ìƒì„±
        graphql_query = generator.generate_api_call_without_llm(
            "ì‚¬ìš©ì ì •ë³´ë¥¼ ì¡°íšŒí•´ì¤˜",
            "graphql"
        )
        print(f"âœ… GraphQL ì¿¼ë¦¬ ìƒì„± (LLM ì—†ì´): {graphql_query}")
        
        # OpenAPI ìš”ì²­ ìƒì„±
        openapi_request = generator.generate_api_call_without_llm(
            "ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤í–‰í•´ì¤˜",
            "openapi"
        )
        print(f"âœ… OpenAPI ìš”ì²­ ìƒì„± (LLM ì—†ì´): {openapi_request}")
    else:
        print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ì–´ì„œ LLM ì—†ì´ API ìƒì„± í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        print("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ í†µí•© API ìƒì„±ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    test_integrated_api_generator_initialization()
    test_api_search()
    test_api_type_detection()
    
    # LLMì´ ìˆëŠ” ê²½ìš° ê³ ê¸‰ í…ŒìŠ¤íŠ¸
    if OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY'):
        test_graphql_query_generation()
        test_openapi_request_generation()
        test_mixed_api_queries()
        test_actual_api_execution()
        test_api_generation_without_llm()
    else:
        print("âš ï¸ OpenAI API í‚¤ê°€ ì—†ì–´ì„œ LLM í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    print("âœ… í†µí•© API ìƒì„±ê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

if __name__ == "__main__":
    main() 